{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable AI - Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Import Libraries and Data](#chapterLibraryData)\n",
    "\n",
    "#### Part 1\n",
    "\n",
    "* [Chapter 1. SHAP - Shapley Additive exPlaination method](#chapter1)\n",
    "   * [Section 1.1 Global Level - Beeswarm plot](#section_1_1)\n",
    "   * [Section 1.2 Local Level - Waterfall plot - Random Row with predicted default class](#section_1_2)\n",
    "   * [Section 1.3 Local Level - Waterfall plot - for all default predictions ](#section_1_3)\n",
    "* [Chapter 2. LIME - Local  Interpretable Model-agnostic Explanations method](#chapter2)\n",
    "   * [Section 2.1 Local Level - Random Row with predicted default class ](#section_2_1)\n",
    "   * [Section 2.2 Local Level - For all default predictions ](#section_2_2)\n",
    "* [Chapter 3. Intersection between SHAP and LIME methods ](#chapter3)\n",
    "   * [Section 3.1 Insights - Exploratory Data Analysis ](#section_3_1)\n",
    "* [Chapter 4. Combination of Chapter 3 with Conformal Prediction ](#chapter4)\n",
    "\n",
    "#### Part 2\n",
    "\n",
    "* [Chapter 1. Guided Prototypes algorithm](#chapter1)\n",
    "  * [Section 1.1 Local Level - Random Row with predicted default class](#section_1_1)\n",
    "  * [Section 1.2 Local Level - for all default predictions](#section_1_2)\n",
    "* [Chapter 2. CEML algorithm](#chapter2)\n",
    "  * [Section 2.1 Local Level - Random Row with predicted default class](#section_2_1)\n",
    "  * [Section 2.2 Local Level - for all default predictions](#section_2_2)\n",
    "* [Chapter 3. Insights - Exploratory Data Analysis](#chapter3)\n",
    "* [Chapter 4. Combination of Chapter 3 with Conformal Prediction](#chapter4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Data <a class=\"anchor\" id=\"chapterLibraryData\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from alibi.explainers import CounterfactualProto\n",
    "import shap\n",
    "from ceml.sklearn import generate_counterfactual\n",
    "import joblib\n",
    "import numpy as np\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = joblib.load('../model/model_rf.joblib')\n",
    "X_test = pd.read_csv('../data/processed/X_test_cp.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SHAP - Shapley Additive exPlaination method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explainer = shap.TreeExplainer(model_rf)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Global Level - Beeswarm plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_index = 1  \n",
    "shap_values_class = shap_values[:, :, class_index]\n",
    "feature_names = X_test.columns\n",
    "shap.summary_plot(shap_values_class, X_test, feature_names=feature_names, max_display=13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 10 most important features for the model's default prediction, sorted by the mean of their absolute SHAP values (their importance) - sum the absoluate SHAP values and then divide by the total number of instances in the dataset.\n",
    "\n",
    "Global level insights:\n",
    "\n",
    "1. As the AMT_CREDIT_SUM_DEBT_bur decreases (a lower value), an applicant is less likely to default (tends to decrease the probabiltiy for class 1).\n",
    "2. If an applicant has its own car (FLAG_OWN_CAR_app), that applicant is less likely to default.\n",
    "3. As the DAYS_LAST_PHONE_CHANGE_app increases, an applicant is less likely to default.\n",
    "4. If an applicant has a Higher Education type, that applicant is less likely to default.\n",
    "5. If an applicant provides home phone (FLAG_HOME_app), that applicant is less likely to default.\n",
    "6. As the DAYS_ID_PUBLISH_app increases, that applicant is less likely to default.\n",
    "7. If an applicant has WEEKDAY_APPR_PROCESS_START_app_THURSDAY, that applicant is less likely to default.\n",
    "8. As the DAYS_EMPLOYED_app increases, an applicant is less likely to default.\n",
    "9. As the REGION_POPULATION_RELATIVE_app increases, an applicant is less likely to default.\n",
    "10. If an applicant has a NAME_INCOME_TYPE_app_State servant, an applicant is less likely to default.\n",
    "\n",
    "The SHAP values consist of 2 elements: magnitude and direction, quantifying the influence of each feature on the model's prediction. The magnitude is the strength of the impact, given by the mean of the features' absolute SHAP values across all instances. The direction is the sign of the contribution, represented by the majority of negative SHAP values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Local Level - Waterfall plot - Random Row with predicted default class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_copy= X_test.copy()\n",
    "X_test_copy.reset_index(inplace=True)\n",
    "X_test_default = X_test.copy()\n",
    "X_test_default['predictions'] = model_rf.predict(X_test)\n",
    "X_test_default.reset_index(inplace=True)\n",
    "X_test_default['original_index'] = X_test_copy.index\n",
    "X_test_default = X_test_default[X_test_default['predictions'] == 1]\n",
    "\n",
    "id_values_predicted_default = X_test_default.original_index.tolist()\n",
    "\n",
    "X_test_default.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_df = pd.DataFrame(shap_values_class, columns=feature_names) # we put the shap values in a dataframe along their corresponding features\n",
    "\n",
    "def generate_waterfall_plot(row_idx):\n",
    "    shap_values_row = shap_df.iloc[row_idx] # we extract the shap values for the row\n",
    "    expected_value = explainer.expected_value[class_index]  # we extract the base value for class_index\n",
    "    waterfall_legacy_plot = shap.plots._waterfall.waterfall_legacy(\n",
    "        expected_value, shap_values_row.values, feature_names=X_test.columns, max_display = 10\n",
    "    )\n",
    "    return waterfall_legacy_plot\n",
    "\n",
    "waterfall_plot_first_row = generate_waterfall_plot(187)\n",
    "waterfall_plot_first_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f(x) = 0.52; the predicted probability for class 1 (default)\n",
    "\n",
    "E[f(x)] = 0.5; the base value, representing the average predicted probability for class 1 (default) - mean prediction\n",
    "\n",
    "f(x) = base value + sum(SHAP values)\n",
    "\n",
    "The figure above illustrates the first 16 most important features for the model's default prediction of the applicant with id 453167, sorted by their numerical contribution on the model's prediction. Each feature contributes to the predicted probability by increasing/decreasing the base value of the instance.\n",
    "\n",
    "The following top 10 features increase the probability of default:\n",
    "\n",
    "OR\n",
    "\n",
    "The following top 10 features contribute to the default prediction:\n",
    "\n",
    "1. FLAG_OWN_CAR (0)\n",
    "2. DAYS_BIRTH_app (31)\n",
    "3. AMT_CREDIT_SUM_DEBT_bur (34.631)\n",
    "4. DAYS_ID_PUBLISH_app (3.346)\n",
    "5. FLAG_PHONE_app (0)\n",
    "6. AMT_GOODS_PRICE_app (472.500)\n",
    "7. FLAG_OWN_REALTY_app (0)\n",
    "8. NAME_EDUCATION_TYPE_app_Higher education (0)\n",
    "9. DAYS_REGISTRATION_app (3.619)\n",
    "10. WEEKDAY_APPR_PROCESS_START_app_THURSDAY (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Local Level - Waterfall plot - for all default predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_index = 1  \n",
    "shap_values_class = shap_values[:, :, class_index] # array data type without SK_ID_CURR index from shap generation\n",
    "shap_df = pd.DataFrame(shap_values_class, columns=feature_names) # dataframe with original index\n",
    "shap_df.index = X_test.index # we pass the SK_ID_CURR index from X_test\n",
    "shap_df.reset_index(inplace=True) # we set the index as column for later merging\n",
    "\n",
    "X_test_default = X_test.copy()\n",
    "X_test_default['predictions'] = model_rf.predict(X_test)\n",
    "X_test_default = X_test_default[X_test_default['predictions'] == 1]\n",
    "X_test_default.reset_index(inplace=True) \n",
    "\n",
    "df = pd.merge(X_test_default,shap_df,how='inner', on='SK_ID_CURR')\n",
    "columns_to_remove = [col for col in df.columns if col.endswith('_x')]\n",
    "df = df.drop(columns=columns_to_remove)\n",
    "df.set_index('SK_ID_CURR', inplace=True)\n",
    "del df[\"predictions\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    df[column] = df[column].apply(lambda x: \"positive\" if x > 0 else \"negative\" if x < 0 else \"no impact\")\n",
    "\n",
    "df.head() \n",
    "\n",
    "for column in df.columns:\n",
    "    df[column] = df[column].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LIME - Local  Interpretable Model-agnostic Explanations method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Local Level - Random Row with predicted default class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_instance = X_test.iloc[187]\n",
    "\n",
    "explainer_lime = LimeTabularExplainer(X_test.values, feature_names=X_test.columns.tolist(), class_names=[\"non-default\",\"default\"], mode='classification', random_state=42)\n",
    "exp = explainer_lime.explain_instance(chosen_instance, model_rf.predict_proba, num_features = 138)\n",
    "\n",
    "exp.show_in_notebook(show_table=True)\n",
    "print(exp.local_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LIME output consists of 3 parts for this instance: the predicted probabilities of the random forest model (left); the feature importance scores (middle), ranked in decreasing order and resulted from the linear regression model and the feature-value table (right).\n",
    "\n",
    "The following top 10 features support the default prediction:\n",
    "\n",
    "OR\n",
    "\n",
    "The following top 10 features significantly decreases the applicant's chance of receiving a loan (being non-default):\n",
    "\n",
    "\n",
    "1. NAME_EDUCATION_TYPE_app_Higher education (0) - not having a higher education\n",
    "2. NAME_INCOME_TYPE_app_State servant (0) - not having a State servant income type\n",
    "3. FLAG_PHONE_app (0) - not having a phone\n",
    "4. FLAG_OWN_CAR_app (0) - not having own car\n",
    "5. NAME_TYPE_SUITE_app_Group of people (0)\n",
    "6. NAME_TYPE_UITE_app_Other_A (0)\n",
    "7. WEEKDAY_APPR_PROCESS_START_app_THURSDAY (0)\n",
    "8. AMT_CREDIT_SUM_DEBT_bur (34.631) - it is more than 19.789\n",
    "9. WEEKDAY_APPR_PROCESS_START_app_SATURDAY (0)\n",
    "10. ORGANIZATION_TYPE_app_Cleaning (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Local Level - For all default predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index_to_name = {i: feature_name for i, feature_name in enumerate(X_test.columns)}\n",
    "\n",
    "row_index = 187\n",
    "row = X_test.iloc[row_index]\n",
    "feature_index = 89\n",
    "feature_name = feature_index_to_name.get(feature_index)\n",
    "\n",
    "feature_value = row.iloc[feature_index]\n",
    "print(f\"The name of the feature at index {feature_index} is: {feature_name}\")\n",
    "print(f\"The value of this feature for the row at index {row_index} is: {feature_value}\")\n",
    "\n",
    "def generate_filter_lime_scores(row):\n",
    "    \n",
    "    chosen_instance = X_test.iloc[row]\n",
    "    explainer_lime = LimeTabularExplainer(X_test.values, feature_names=X_test.columns.tolist(), class_names=[\"non-default\", \"default\"], mode='classification', random_state=42)\n",
    "    exp = explainer_lime.explain_instance(chosen_instance, model_rf.predict_proba, num_features=len(X_test.columns))\n",
    "    \n",
    "    print(exp.local_exp)\n",
    "    val = exp.local_exp[1]\n",
    "    filtered_exp = [tup for tup in val if tup[0] == 89]\n",
    "    print(filtered_exp)\n",
    "\n",
    "generate_filter_lime_scores(187)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_scores = []\n",
    "\n",
    "def generate_lime_scores(row):\n",
    "    \n",
    "    chosen_instance = X_test.loc[row]\n",
    "    explainer_lime = LimeTabularExplainer(X_test.values, feature_names=X_test.columns.tolist(), class_names=[\"non-default\", \"default\"], mode='classification', random_state=42)\n",
    "    exp = explainer_lime.explain_instance(chosen_instance, model_rf.predict_proba, num_features=len(X_test.columns))\n",
    "    lime_scores_row = {feature_index_to_name[i]: round(score, 2) for i, score in exp.local_exp[1]}\n",
    "\n",
    "    return lime_scores_row\n",
    "\n",
    "X_test_default = X_test.copy()\n",
    "X_test_default['predictions'] = model_rf.predict(X_test)\n",
    "X_test_default = X_test_default[X_test_default['predictions'] == 1]\n",
    "del X_test_default['predictions']\n",
    "\n",
    "for idx, row in X_test_default.iterrows():\n",
    "    lime_scores_row = generate_lime_scores(idx)\n",
    "    lime_scores.append(lime_scores_row)\n",
    "\n",
    "lime_scores_df = pd.DataFrame(lime_scores)\n",
    "lime_scores_df.index = X_test_default.index\n",
    "lime_scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 12\n",
    "specific_row = lime_scores_df.loc[453167]\n",
    "value_check = specific_row[\"ORGANIZATION_TYPE_app_Industry: type 12\"]\n",
    "value_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in lime_scores_df.columns:\n",
    "    lime_scores_df[column] = lime_scores_df[column].apply(lambda x: \"positive\" if x > 0 else \"negative\" if x < 0 else \"no impact\")\n",
    "lime_scores_df.head()\n",
    "\n",
    "# It is important to note that LIME produces a specific output for the variables of continous data type, namely interval explanations\n",
    "# To ease the computation of the task of solely retaining the rows with common explanations between SHAP and LIME methods, the interval explanations\n",
    "# are later added to the final randomly selected default instances, in their original format before applying MinMax scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in lime_scores_df.columns:\n",
    "    lime_scores_df[column] = lime_scores_df[column].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Intersection between SHAP and LIME methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [col[:-2] if col.endswith('_y') else col for col in df.columns]\n",
    "display(df.head())\n",
    "display(lime_scores_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns = df.columns.intersection(lime_scores_df.columns)\n",
    "\n",
    "result_data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    result_row = {}\n",
    "    for col in common_columns:\n",
    "        if row[col] == lime_scores_df.loc[index, col]: # we compare the value of the current column in df with the corresponding value in lime_scores_df\n",
    "            result_row[col] = row[col] # if they are equal, then we store that value in the newdataset for that column\n",
    "        else:\n",
    "            result_row[col] = \"no match\" # if they are not equal, then we store \"no match\"\n",
    "            \n",
    "    result_data.append(result_row)\n",
    "\n",
    "result_df = pd.DataFrame(result_data, index=df.index, columns=common_columns)\n",
    "\n",
    "no_match_columns = result_df.columns[result_df.eq(\"no match\").all()]\n",
    "result_df.drop(columns=no_match_columns, inplace=True) # from 138 to 106\n",
    "\n",
    "cols_to_drop = result_df.columns[((result_df == \"no match\") | (result_df == \"negative\")).all(axis=0)]\n",
    "result_df.drop(cols_to_drop, axis=1, inplace=True) # from 106 to 98\n",
    "\n",
    "no_match_columns = result_df.columns[result_df.eq(\"no impact\").all()]\n",
    "result_df.drop(columns=no_match_columns, inplace=True) # from 98 to 94\n",
    "\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = result_df.loc[453167, result_df.loc[453167] == 'positive']\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = result_df.loc[209065, result_df.loc[209065] == 'positive']\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Insights - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame()\n",
    "\n",
    "def calculate_percentage(row, value):\n",
    "    total = len(row)\n",
    "    value_count = row.value_counts().get(value, 0)\n",
    "    return (value_count / total) * 100\n",
    "\n",
    "for value in ['positive', 'negative', 'no match', 'no impact']:\n",
    "    percentage_column_name = f'percentage_{value}'\n",
    "    dataframe[percentage_column_name] = result_df.apply(lambda row: calculate_percentage(row, value), axis=1)\n",
    "\n",
    "del dataframe[\"percentage_no impact\"]\n",
    "\n",
    "dataframe= dataframe.round().astype(int)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_averages = dataframe.mean()\n",
    "print(column_averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.replace({'no match': 'not applicable', 'negative': 'not applicable'}, inplace=True)\n",
    "\n",
    "dataframe = pd.DataFrame()\n",
    "\n",
    "def calculate_percentage(row, value):\n",
    "    total = len(row)\n",
    "    value_count = row.value_counts().get(value, 0)\n",
    "    return (value_count / total) * 100\n",
    "\n",
    "for value in ['positive', 'not applicable']:\n",
    "    percentage_column_name = f'percentage_{value}'\n",
    "    dataframe[percentage_column_name] = result_df.apply(lambda row: calculate_percentage(row, value), axis=1)\n",
    "\n",
    "dataframe = dataframe.round().astype(int)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_averages = dataframe.mean()\n",
    "print(column_averages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Combination of Chapter 3 with Conformal Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = pd.read_csv(\"../data/processed/conformal_prediction.csv\")\n",
    "dataframe.reset_index(inplace=True)\n",
    "display(dataframe.head())\n",
    "display(cp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(cp, dataframe, on='SK_ID_CURR', how='inner')\n",
    "merged_df = merged_df[[\"SK_ID_CURR\",\"percentage_positive\",\"percentage_not applicable\",\"level\"]]\n",
    "merged_df.set_index('SK_ID_CURR', inplace=True) \n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"level\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_per_group = merged_df.groupby('level').mean()\n",
    "means_per_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = joblib.load('../model/model_rf.joblib')\n",
    "X_test = pd.read_csv('../data/processed/X_test_cp.csv',index_col=0)\n",
    "X_train = pd.read_csv('../data/processed/X_remaining_cp.csv',index_col=0)\n",
    "\n",
    "X_test_default = X_test.copy()\n",
    "X_test_default['predictions'] = model_rf.predict(X_test)\n",
    "X_test_default = X_test_default[X_test_default['predictions'] == 1]\n",
    "X_test_default.reset_index(inplace=True) \n",
    "\n",
    "del X_test_default['predictions']\n",
    "X_test_default.set_index('SK_ID_CURR', inplace=True)\n",
    "\n",
    "X_test_default.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Guided Prototypes algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Local level - Random row with predicted default class <a class=\"anchor\" id=\"chapterdefaultrow\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.to_numpy()\n",
    "X_train = X_train.to_numpy()\n",
    "\n",
    "X = X_test[187].reshape((1,) + X_test[187].shape)\n",
    "shape = X.shape\n",
    "\n",
    "cf = CounterfactualProto(model_rf.predict_proba, shape)\n",
    "\n",
    "cf.fit(X_train)\n",
    "\n",
    "explanation = cf.explain(X)\n",
    "\n",
    "CF = np.array([explanation['data']['cf']['X'][0]])\n",
    "\n",
    "print(f'Original prediction: {explanation.orig_class}')\n",
    "print(f'Counterfactual prediction: {explanation.cf[\"class\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = joblib.load('../model/model_rf.joblib')\n",
    "X_test = pd.read_csv('../data/processed/X_test_cp.csv',index_col=0)\n",
    "X_train = pd.read_csv('../data/processed/X_remaining_cp.csv',index_col=0)\n",
    "\n",
    "X_test_default = X_test.copy()\n",
    "X_test_default['predictions'] = model_rf.predict(X_test)\n",
    "X_test_default = X_test_default[X_test_default['predictions'] == 1]\n",
    "X_test_default.reset_index(inplace=True) \n",
    "\n",
    "del X_test_default['predictions']\n",
    "X_test_default.set_index('SK_ID_CURR', inplace=True)\n",
    "\n",
    "X_test_default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reshaped = X.flatten() # Reshape X and CF to be 1-dimensional arrays\n",
    "CF_reshaped = CF.flatten()\n",
    "\n",
    "differences = CF_reshaped - X_reshaped\n",
    "\n",
    "df_diff = pd.DataFrame({'Features': X_test.columns,'Original': X_reshaped,'CF': CF_reshaped,'Difference': differences})\n",
    "df_diff_filtered = df_diff[df_diff['Difference'] != 0]\n",
    "df_diff_filtered['Result'] = df_diff_filtered['Difference'].apply(lambda x: 'higher' if x > 0 else 'lower')\n",
    "print(df_diff_filtered.shape)\n",
    "\n",
    "df_diff_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Local level - for all default predictions <a class=\"anchor\" id=\"chapteralldefaultrows\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = CounterfactualProto(model_rf.predict_proba, shape)\n",
    "cf.fit(X_train)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, row in tqdm(X_test_default.iterrows(), total=len(X_test_default)):\n",
    "\n",
    "    X = row.values.reshape(1, -1)  # Reshape the row to be 2-dimensional\n",
    "    explanation = cf.explain(X)\n",
    "    \n",
    "    if explanation is not None and explanation.cf is not None and 'X' in explanation.cf:\n",
    "\n",
    "        differences = explanation.cf['X'] - X\n",
    "        \n",
    "        feature_results = []\n",
    "        for j, diff in enumerate(differences.flatten()):\n",
    "            if diff == 0:\n",
    "                feature_results.append('not applicable')\n",
    "            elif diff < 0:\n",
    "                feature_results.append('lower')\n",
    "            else:\n",
    "                feature_results.append('higher')\n",
    " \n",
    "        results.append(feature_results)\n",
    "\n",
    "    else:\n",
    "\n",
    "        results.append(['not found'] * len(X_test.columns))  # If no counterfactual explanation was found, append 'not found' for all features\n",
    "\n",
    "result_df = pd.DataFrame(results, columns=X_test.columns)\n",
    "print(result_df.shape)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = result_df.columns[result_df.eq('not applicable').all()] # We remove the columns that had no difference\n",
    "result_df = result_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CEML algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Local level - Random row with predicted default class <a class=\"anchor\" id=\"chapterdefaultrow\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.to_numpy()\n",
    "x = X_test[187,:]\n",
    "\n",
    "result_ceml = generate_counterfactual(model_rf, x, y_target=0)\n",
    "x_cf_array = result_ceml['x_cf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_test_default.columns.tolist()\n",
    "df_ceml = pd.DataFrame({0: x_cf_array})\n",
    "\n",
    "df_ceml_transposed = df_ceml.T\n",
    "df_ceml_transposed.columns = feature_names\n",
    "df_ceml_transposed[\"DAYS_LAST_PHONE_CHANGE_app\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_test_default.columns.tolist()\n",
    "df_ceml = pd.DataFrame({0: x_cf_array})\n",
    "\n",
    "df_ceml_transposed = df_ceml.T\n",
    "df_ceml_transposed.columns = feature_names\n",
    "\n",
    "def format_non_scientific(x):\n",
    "    return \"{:.10f}\".format(x)\n",
    "\n",
    "pd.set_option('display.float_format', format_non_scientific)\n",
    "\n",
    "df_ceml_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_test_default.columns.tolist()\n",
    "df_ceml = pd.DataFrame({0: x_cf_array})\n",
    "\n",
    "df_ceml_transposed = df_ceml.T\n",
    "df_ceml_transposed.columns = feature_names\n",
    "\n",
    "discrete_numerical_features = ['TARGET_app', 'NAME_CONTRACT_TYPE_app', 'CODE_GENDER_app', 'FLAG_OWN_CAR_app', 'FLAG_OWN_REALTY_app', 'CNT_CHILDREN_app', 'FLAG_MOBIL_app', 'FLAG_EMP_PHONE_app', 'FLAG_WORK_PHONE_app', 'FLAG_CONT_MOBILE_app', 'FLAG_PHONE_app', 'FLAG_EMAIL_app', 'HOUR_APPR_PROCESS_START_app', 'REG_REGION_NOT_LIVE_REGION_app', 'REG_REGION_NOT_WORK_REGION_app', 'REG_CITY_NOT_LIVE_CITY_app', 'LIVE_CITY_NOT_WORK_CITY_app', 'OBS_30_CNT_SOCIAL_CIRCLE_app', 'OBS_60_CNT_SOCIAL_CIRCLE_app', 'AMT_REQ_CREDIT_BUREAU_YEAR_app', 'CREDIT_CURRENCY_bur', 'NAME_TYPE_SUITE_app_Children', 'NAME_TYPE_SUITE_app_Family', 'NAME_TYPE_SUITE_app_Group of people', 'NAME_TYPE_SUITE_app_Other_A', 'NAME_TYPE_SUITE_app_Other_B', 'NAME_TYPE_SUITE_app_Spouse, partner', 'NAME_TYPE_SUITE_app_Unaccompanied', 'NAME_INCOME_TYPE_app_Businessman', 'NAME_INCOME_TYPE_app_Commercial associate', 'NAME_INCOME_TYPE_app_State servant', 'NAME_INCOME_TYPE_app_Student', 'NAME_INCOME_TYPE_app_Working', 'NAME_EDUCATION_TYPE_app_Academic degree', 'NAME_EDUCATION_TYPE_app_Higher education', 'NAME_EDUCATION_TYPE_app_Incomplete higher', 'NAME_EDUCATION_TYPE_app_Lower secondary', 'NAME_EDUCATION_TYPE_app_Secondary / secondary special', 'NAME_FAMILY_STATUS_app_Civil marriage', 'NAME_FAMILY_STATUS_app_Married', 'NAME_FAMILY_STATUS_app_Separated', 'NAME_FAMILY_STATUS_app_Single / not married', 'NAME_FAMILY_STATUS_app_Widow', 'NAME_HOUSING_TYPE_app_Co-op apartment', 'NAME_HOUSING_TYPE_app_House / apartment', 'NAME_HOUSING_TYPE_app_Municipal apartment', 'NAME_HOUSING_TYPE_app_Office apartment', 'NAME_HOUSING_TYPE_app_Rented apartment', 'NAME_HOUSING_TYPE_app_With parents', 'REGION_RATING_CLIENT_app_1', 'REGION_RATING_CLIENT_app_2', 'REGION_RATING_CLIENT_app_3', 'WEEKDAY_APPR_PROCESS_START_app_FRIDAY', 'WEEKDAY_APPR_PROCESS_START_app_MONDAY', 'WEEKDAY_APPR_PROCESS_START_app_SATURDAY', 'WEEKDAY_APPR_PROCESS_START_app_SUNDAY', 'WEEKDAY_APPR_PROCESS_START_app_THURSDAY', 'WEEKDAY_APPR_PROCESS_START_app_TUESDAY', 'WEEKDAY_APPR_PROCESS_START_app_WEDNESDAY', 'ORGANIZATION_TYPE_app_Advertising', 'ORGANIZATION_TYPE_app_Agriculture', 'ORGANIZATION_TYPE_app_Bank', 'ORGANIZATION_TYPE_app_Business Entity Type 1', 'ORGANIZATION_TYPE_app_Business Entity Type 2', 'ORGANIZATION_TYPE_app_Business Entity Type 3', 'ORGANIZATION_TYPE_app_Cleaning', 'ORGANIZATION_TYPE_app_Construction', 'ORGANIZATION_TYPE_app_Culture', 'ORGANIZATION_TYPE_app_Electricity', 'ORGANIZATION_TYPE_app_Emergency', 'ORGANIZATION_TYPE_app_Government', 'ORGANIZATION_TYPE_app_Hotel', 'ORGANIZATION_TYPE_app_Housing', 'ORGANIZATION_TYPE_app_Industry: type 1', 'ORGANIZATION_TYPE_app_Industry: type 10', 'ORGANIZATION_TYPE_app_Industry: type 11', 'ORGANIZATION_TYPE_app_Industry: type 12', 'ORGANIZATION_TYPE_app_Industry: type 13', 'ORGANIZATION_TYPE_app_Industry: type 2', 'ORGANIZATION_TYPE_app_Industry: type 3', 'ORGANIZATION_TYPE_app_Industry: type 4', 'ORGANIZATION_TYPE_app_Industry: type 5', 'ORGANIZATION_TYPE_app_Industry: type 6', 'ORGANIZATION_TYPE_app_Industry: type 7', 'ORGANIZATION_TYPE_app_Industry: type 9', 'ORGANIZATION_TYPE_app_Insurance', 'ORGANIZATION_TYPE_app_Kindergarten', 'ORGANIZATION_TYPE_app_Legal Services', 'ORGANIZATION_TYPE_app_Medicine', 'ORGANIZATION_TYPE_app_Military', 'ORGANIZATION_TYPE_app_Mobile', 'ORGANIZATION_TYPE_app_Other', 'ORGANIZATION_TYPE_app_Police', 'ORGANIZATION_TYPE_app_Postal', 'ORGANIZATION_TYPE_app_Realtor', 'ORGANIZATION_TYPE_app_Religion', 'ORGANIZATION_TYPE_app_Restaurant', 'ORGANIZATION_TYPE_app_School', 'ORGANIZATION_TYPE_app_Security', 'ORGANIZATION_TYPE_app_Security Ministries', 'ORGANIZATION_TYPE_app_Self-employed', 'ORGANIZATION_TYPE_app_Services', 'ORGANIZATION_TYPE_app_Telecom', 'ORGANIZATION_TYPE_app_Trade: type 1', 'ORGANIZATION_TYPE_app_Trade: type 2', 'ORGANIZATION_TYPE_app_Trade: type 3', 'ORGANIZATION_TYPE_app_Trade: type 4', 'ORGANIZATION_TYPE_app_Trade: type 5', 'ORGANIZATION_TYPE_app_Trade: type 6', 'ORGANIZATION_TYPE_app_Trade: type 7', 'ORGANIZATION_TYPE_app_Transport: type 1', 'ORGANIZATION_TYPE_app_Transport: type 2', 'ORGANIZATION_TYPE_app_Transport: type 3', 'ORGANIZATION_TYPE_app_Transport: type 4', 'ORGANIZATION_TYPE_app_University', 'CREDIT_ACTIVE_bur_Active', 'CREDIT_ACTIVE_bur_Closed', 'CREDIT_ACTIVE_bur_Sold', 'CREDIT_TYPE_bur_Another type of loan', 'CREDIT_TYPE_bur_Car loan', 'CREDIT_TYPE_bur_Consumer credit', 'CREDIT_TYPE_bur_Credit card', 'CREDIT_TYPE_bur_Loan for business development', 'CREDIT_TYPE_bur_Microloan', 'CREDIT_TYPE_bur_Mortgage']\n",
    "filtered_columns = list(set(discrete_numerical_features) & set(df_ceml_transposed.columns))\n",
    "\n",
    "filtered_ceml = df_ceml_transposed.drop(columns=filtered_columns)\n",
    "\n",
    "df_ceml_original = pd.DataFrame({0: x})\n",
    "\n",
    "df_ceml_transposed_original = df_ceml_original.T\n",
    "df_ceml_transposed_original.columns = feature_names\n",
    "\n",
    "filtered_columns = list(set(discrete_numerical_features) & set(df_ceml_transposed_original.columns))\n",
    "filtered_original = df_ceml_transposed_original.drop(columns=filtered_columns)\n",
    "\n",
    "filtered_original = filtered_original.astype(float)\n",
    "filtered_ceml = filtered_ceml.astype(float)\n",
    "\n",
    "threshold = 0.0000000001\n",
    "absolute_diff = np.abs(filtered_ceml - filtered_original)\n",
    "subtracted_df = (filtered_ceml - filtered_original).mask(absolute_diff < threshold, 0)\n",
    "\n",
    "columns = subtracted_df.columns[subtracted_df.eq(0).all()]\n",
    "subtracted_df.drop(columns=columns, inplace=True) # we drop the columns with 0 difference\n",
    "display(subtracted_df)\n",
    "subtracted_df = subtracted_df.applymap(lambda x: \"higher\" if x > 0 else (\"lower\" if x < 0 else x))\n",
    "display(subtracted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Local level - for all default predictions <a class=\"anchor\" id=\"chapteralldefaultrows\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df = pd.DataFrame(index=X_test_default.index, columns=X_test_default.columns)\n",
    "\n",
    "for index, row in tqdm(X_test_default.iterrows(), total=len(X_test_default)):\n",
    "\n",
    "    row = row.values\n",
    "    result_ceml = generate_counterfactual(model_rf, row, y_target=0)\n",
    "    \n",
    "\n",
    "    if result_ceml is not None and 'x_cf' in result_ceml:\n",
    "        x_cf_array = result_ceml['x_cf']\n",
    "        differences = x_cf_array - row\n",
    "        \n",
    "        feature_results = []\n",
    "        for j, diff in enumerate(differences.flatten()):\n",
    "            if diff == 0:\n",
    "                feature_results.append('not applicable')\n",
    "            elif diff < 0:\n",
    "                feature_results.append('lower')\n",
    "            else:\n",
    "                feature_results.append('higher')\n",
    "        \n",
    "        classification_df.loc[index] = feature_results\n",
    "\n",
    "    else:\n",
    "\n",
    "        classification_df.loc[index] = ['not found'] * len(X_test_default.columns)\n",
    "\n",
    "classification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns = result_df.columns.intersection(classification_df.columns)\n",
    "\n",
    "result_data = []\n",
    "\n",
    "for result_row, classification_row in zip(result_df.itertuples(), classification_df.itertuples()):\n",
    "    result_row_data = {}\n",
    "    for col in common_columns:\n",
    "        result_value = getattr(result_row, col)\n",
    "        classification_value = getattr(classification_row, col)\n",
    "        if result_value == classification_value:\n",
    "            result_row_data[col] = result_value\n",
    "        else:\n",
    "            result_row_data[col] = \"no match\"\n",
    "    result_data.append(result_row_data)\n",
    "\n",
    "result = pd.DataFrame(result_data, index=classification_df.index, columns=common_columns)\n",
    "\n",
    "columns_to_drop = result.columns[result.eq('not applicable').all()]\n",
    "result = result.drop(columns=columns_to_drop)\n",
    "no_match_columns = result.columns[result.eq(\"no match\").all()]\n",
    "result.drop(columns=no_match_columns, inplace=True)\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.replace({'no match': 'not applicable'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Insights - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame()\n",
    "\n",
    "def calculate_percentage(row, value):\n",
    "    total = len(row)\n",
    "    value_count = row.value_counts().get(value, 0)\n",
    "    return (value_count / total) * 100\n",
    "\n",
    "for value in ['higher', 'lower', 'not applicable']:\n",
    "    percentage_column_name = f'percentage_{value}'\n",
    "    dataframe[percentage_column_name] = result.apply(lambda row: calculate_percentage(row, value), axis=1)\n",
    "\n",
    "dataframe= dataframe.round().astype(int)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_averages = dataframe.mean()\n",
    "print(column_averages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Combination of Chapter 3 with Conformal Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = pd.read_csv(\"../data/processed/conformal_prediction.csv\")\n",
    "dataframe.reset_index(inplace=True)\n",
    "display(dataframe.head())\n",
    "display(cp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(cp, dataframe, on='SK_ID_CURR', how='inner')\n",
    "merged_df = merged_df[[\"SK_ID_CURR\",\"percentage_higher\",\"percentage_lower\",\"percentage_not applicable\",\"level\"]]\n",
    "merged_df.set_index('SK_ID_CURR', inplace=True) \n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_per_group = merged_df.groupby('level').mean()\n",
    "means_per_group"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
